{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Sjv263Z1cFkl",
        "TKGKuIBTcQpE",
        "t8E9Et66c397",
        "3ZJ-fqDYcj0p",
        "EoTSxUuDRT8O",
        "bxQkBFSsPZSf",
        "MVf2aQvm8zPc",
        "uUwLXw0mHMaj"
      ],
      "authorship_tag": "ABX9TyNdsdIORjCkLAsyWOVYsQfe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaiMejia/ML-Projects/blob/main/Backtesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <b> Bitcoin Trading Agent - Backtesting</b>"
      ],
      "metadata": {
        "id": "l8Tyzt7Rbeyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Context</b>"
      ],
      "metadata": {
        "id": "Sjv263Z1cFkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Background:</b>\n",
        "<br>We are a fintech company focused on cryptocurrency trading building a smart bitcoin trading system designed to operate with minimal human supervision and continuously adapt to changing market conditions. The agent must dynamically manage budget allocation, shift between strategies, and make autonomous trading decisions while running 24/7.\n",
        "\n",
        "This project will give you experience with real-time algorithmic trading, feature engineering in a volatile domain, LLM-assisted decision-making, and deploying robust, cloud-based AI systems that bridge automation with finance.\n",
        "\n",
        "<b>Project Objectives:</b>\n",
        "- Accept a configurable budget (e.g., $1K - 100K)\n",
        "- Use Dollar-Cost Averaging (DCA) to accumulate more bitcoin when prices drop, distributing buys over time or price levels\n",
        "- Implement an ATR-based stop-loss strategy to manage short-term trades and avoid excessive loss exposure\n",
        "- Switch between different strategies (e.g., day trading, swing trading, value investing)\n",
        "- Adapt continuously to market conditions, ideally with the help of a lightweight LLM\n",
        "- Run 24/7 and deploy in a cloud environment\n",
        "- Send Telegram notifications for each trade made\n",
        "- Send a weekly email report every Monday at 9:00AM via Gmail\n"
      ],
      "metadata": {
        "id": "v_sZJP85bg5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>1. Installing and loading libraries</b>"
      ],
      "metadata": {
        "id": "TKGKuIBTcQpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. AUTOMATIC LIBRARY INSTALLATION ---\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "# --------------------------------------------------\n",
        "\n",
        "REQUIRED_LIBRARIES = [\n",
        "    ('pandas-ta', 'pandas_ta'),\n",
        "    ('yfinance', 'yfinance'),\n",
        "    ('numpy', 'numpy'),              # PyPI: numpy, Import: numpy\n",
        "    ('pandas', 'pandas'),            # PyPI: pandas, Import: pandas\n",
        "    ('scikit-learn', 'sklearn'),    # PyPI: scikit-learn, Import: sklearn\n",
        "    ('gspread', 'gspread'),\n",
        "    ('oauth2client', 'oauth2client'),\n",
        "]\n",
        "\n",
        "def install_libraries(libraries):\n",
        "    \"\"\"Installs missing Python libraries using pip.\"\"\"\n",
        "    print(\"Checking for required libraries...\")\n",
        "\n",
        "    for pypi_name, import_name in libraries:\n",
        "        try:\n",
        "            # Check for the *import* name\n",
        "            __import__(import_name)\n",
        "        except ImportError:\n",
        "            print(f\"'{import_name}' not found. Attempting to install '{pypi_name}'...\")\n",
        "            try:\n",
        "                # Install using the *PyPI* name\n",
        "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pypi_name, '--quiet'])\n",
        "                print(f\"Successfully installed {pypi_name}.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"Error installing {pypi_name}: {e}\")\n",
        "\n",
        "\n",
        "install_libraries(REQUIRED_LIBRARIES)"
      ],
      "metadata": {
        "id": "_GYO0k8KJBIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899dcecb-bbd7-42b2-a626-85aee1c7d04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for required libraries...\n",
            "'pandas_ta' not found. Attempting to install 'pandas-ta'...\n",
            "Successfully installed pandas-ta.\n",
            "'sklearn' not found. Attempting to install 'scikit-learn'...\n",
            "Successfully installed scikit-learn.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports follow the installation block\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any, Tuple, Optional\n",
        "import time # Added for potential delays\n",
        "import requests\n",
        "\n",
        "import yfinance as yf\n",
        "import json\n",
        "import pandas_ta\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V9hXnFYC1-c",
        "outputId": "e22ccf28-8a33-47ad-af8d-b72963765020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Data Retrival</b>"
      ],
      "metadata": {
        "id": "t8E9Et66c397"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -------------------------------------------------------- ##\n",
        "# ------------- DATA RETRIEVAL  -------\n",
        "## -------------------------------------------------------- ##\n",
        "\n",
        "# --- CONFIGURATION (Change these values to adjust the data) ---\n",
        "TICKER = 'BTC-USD'\n",
        "HISTORY_START_DATE = '2023-01-01' # Fetch the last 2 years of data\n",
        "HISTORY_INTERVAL = '1d'\n",
        "\n",
        "# Define where to save the file\n",
        "SAVE_FOLDER = '/content/drive/MyDrive/ColabNotebooks/Proj5/data_btc'\n",
        "FULL_PATH = os.path.join(SAVE_FOLDER, \"btcdata.csv\")\n",
        "\n",
        "\n",
        "def fetch_and_save_data(ticker, start_date, interval, save_path):\n",
        "    \"\"\"\n",
        "    Fetches historical data for the configured Ticker and saves it to a CSV file.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use yfinance.download for the simplest fetching method\n",
        "        data = yf.download(\n",
        "            tickers=ticker,\n",
        "            start=start_date,\n",
        "            interval=interval\n",
        "        )\n",
        "\n",
        "        if data.empty:\n",
        "            print(\"‚ùå Error: No data returned from yfinance.\")\n",
        "            return\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "              # Flatten the MultiIndex to a single index of (Price_Type, Ticker) tuples\n",
        "              data.columns = data.columns.to_flat_index()\n",
        "              # Convert the tuples to cleaner string names like 'Close_BTC-USD'\n",
        "              # You can customize this, but for a single ticker, the first element is enough\n",
        "              data.columns = [col[0] for col in data.columns]\n",
        "        else:\n",
        "              data.columns = [col for col in data.columns]\n",
        "\n",
        "        # Clean up columns: Rename 'Adj Close' to 'Close' and drop redundant columns\n",
        "        data = data.rename(columns={\"Adj Close\": \"Close\"}, errors='ignore')\n",
        "        df_final = data.drop(columns=['Dividends', 'Stock Splits', 'Repaired?'], errors='ignore')\n",
        "\n",
        "        # 2. Prepare the save location\n",
        "        os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
        "\n",
        "        # 3. Save the final dataset (overwrites the file every time)\n",
        "        df_final.to_csv(save_path, index=True)\n",
        "\n",
        "    except Exception as e:\n",
        "            print(f\"‚ùå A critical error occurred during fetching or saving: {e}\")\n",
        "\n",
        "\n",
        "# --- GETTING THE DATASET ---\n",
        "fetch_and_save_data(\n",
        "    TICKER,\n",
        "    HISTORY_START_DATE,\n",
        "    HISTORY_INTERVAL,\n",
        "    FULL_PATH\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tFi9_rPcjNS",
        "outputId": "235d9735-8314-4c52-e2c4-f38192d5832e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Data Processing</b>"
      ],
      "metadata": {
        "id": "3ZJ-fqDYcj0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -------------------------------------------------------------- ##\n",
        "# -------------  DATA PROCESSING & ADDING TA INDICATORS   -------\n",
        "## -------------------------------------------------------------- ##\n",
        "\n",
        "\n",
        "# --- CONFIGURATION (Ensure these paths match your retrieval script) ---\n",
        "SAVE_FOLDER = '/content/drive/MyDrive/ColabNotebooks/Proj5/data_btc'\n",
        "RAW_PATH = os.path.join(SAVE_FOLDER, \"btcdata.csv\")\n",
        "PROCESSED_FILE = os.path.join(SAVE_FOLDER, \"btc_procdata.csv\")\n",
        "\n",
        "def process_data_and_add_features():\n",
        "    \"\"\"\n",
        "    Loads raw data, adds essential features (EMA, RSI, ATR, MACD, Lag),\n",
        "    drops NaNs, and saves the final DataFrame, ensuring all strategy inputs are present.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(RAW_PATH):\n",
        "        print(f\"‚ùå Error: Raw data file not found at {RAW_PATH}.\")\n",
        "        return\n",
        "\n",
        "    # 1. Load the raw data\n",
        "    df = pd.read_csv(RAW_PATH, index_col=0, parse_dates=True)\n",
        "\n",
        "    # Coerce price columns to numeric and drop rows where price data is missing\n",
        "    numeric_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    for col in numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "    original_length = len(df)\n",
        "\n",
        "    # 2. Add ALL KEY Technical Analysis Indicators using pandas-ta lib\n",
        "    df.ta.ema(length=20, append=True)                # EMA (Exponential Moving Average) - Adds 'EMA_20'\n",
        "    df.ta.rsi(length=14, append=True)                # RSI (Relative Strength Index) - Adds 'RSI_14'\n",
        "    df.ta.atr(length=14, append=True)                # ATR (Average True Range) - Adds 'ATR_14'\n",
        "\n",
        "    # MACD (Moving Average Convergence Divergence) - Adds 'MACD_12_26_9', 'MACDH_12_26_9', 'MACDS_12_26_9'\n",
        "    df.ta.macd(append=True)                           # MACD is crucial for the SWING_TRADE strategy logic\n",
        "    df['Close_Lag_1'] = df['Close'].shift(1)          # LAG Add Lagged Feature\n",
        "\n",
        "    # 3. Clean up and Save\n",
        "    df.dropna(inplace=True)   # Drop rows that are NaN due to the indicator lookback period\n",
        "\n",
        "    # RENAME COLUMNS FOR SIMPLICITY in the trading script (matching your expected variables)\n",
        "    df.rename(columns={\n",
        "        'ATRr_14': 'ATR',\n",
        "        'RSI_14': 'RSI',\n",
        "        'EMA_20': 'EMA_20',\n",
        "        'MACD_12_26_9': 'MACD',\n",
        "        'MACDs_12_26_9': 'MACD_Signal'\n",
        "        # MACDH is the Histogram, not directly used in the switch logic, so we omit renaming it\n",
        "    }, inplace=True)\n",
        "\n",
        "    os.makedirs(SAVE_FOLDER, exist_ok=True)    # Ensure folder exists\n",
        "    df.to_csv(PROCESSED_FILE, index=True)     # Save the processed data\n",
        "\n",
        "    print(f\"‚úÖ Data processed and saved to {PROCESSED_FILE}.\")\n",
        "    print(f\"   Indicators added: RSI, ATR, EMA_20, MACD, MACD_Signal.\")\n",
        "    print(f\"   Final Rows: {len(df)} (Dropped {original_length - len(df)} rows for lookback)\")\n",
        "    # print(df.tail(1)[['Close', 'RSI', 'MACD', 'MACD_Signal', 'ATR', 'EMA_20']])\n",
        "\n",
        "process_data_and_add_features()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDVaS8TWcjLg",
        "outputId": "68122717-03fc-4a5f-bfd6-cd7d177f5a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data processed and saved to /content/drive/MyDrive/ColabNotebooks/Proj5/data_btc/btc_procdata.csv.\n",
            "   Indicators added: RSI, ATR, EMA_20, MACD, MACD_Signal.\n",
            "   Final Rows: 1006 (Dropped 33 rows for lookback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Loading the TA and Sentiment Data</b>"
      ],
      "metadata": {
        "id": "EoTSxUuDRT8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ---------------------------------------------------------------- ##\n",
        "# üöÄ BLOCK 1: LOAD AND PREPARE ALL RAW/EXTERNAL DATA (TA & FGI)\n",
        "# --- Includes Date Filtering for Backtesting ---\n",
        "## ---------------------------------------------------------------- ##\n",
        "\n",
        "\n",
        "# --- CONFIGURATION (Ensure this aligns with your Colab drive) ---\n",
        "SAVE_FOLDER = '/content/drive/MyDrive/ColabNotebooks/Proj5/data_btc'\n",
        "PROCESSED_FILE = os.path.join(SAVE_FOLDER, \"btc_procdata.csv\")\n",
        "CLEANED_TA_FILE = os.path.join(SAVE_FOLDER, \"btc_cleaned_ta_data.csv\") # Output 1\n",
        "FGI_PROCESSED_FILE = os.path.join(SAVE_FOLDER, \"btc_fgi_data.csv\")     # Output 2\n",
        "FGI_API_URL = \"https://api.alternative.me/fng/?limit=0&format=json\"\n",
        "START_DATE_FILTER = '2023-01-01' # <-- CRITICAL FILTER ADDED HERE\n",
        "\n",
        "def fetch_and_process_fgi_data():\n",
        "    \"\"\"Fetches and saves historical Fear & Greed Index data.\"\"\"\n",
        "    # (Function remains the same as FGI data is fetched in full and merged later)\n",
        "    print(\"‚è≥ Fetching historical F&G Index data...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(FGI_API_URL, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        data = response.json().get('data')\n",
        "        if not data: return None\n",
        "\n",
        "        fgi_df = pd.DataFrame(data)\n",
        "        fgi_df['date'] = pd.to_datetime(fgi_df['timestamp'].astype(int), unit='s')\n",
        "        fgi_df['value'] = pd.to_numeric(fgi_df['value'], errors='coerce')\n",
        "        fgi_df = fgi_df[['date', 'value', 'value_classification']].copy()\n",
        "        fgi_df.set_index('date', inplace=True)\n",
        "        fgi_df.rename(columns={'value': 'FGI_Score', 'value_classification': 'FGI_Sentiment'}, inplace=True)\n",
        "        fgi_df.sort_index(inplace=True)\n",
        "\n",
        "        os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
        "        fgi_df.to_csv(FGI_PROCESSED_FILE, index=True)\n",
        "        print(f\"‚úÖ FGI data retrieved and saved to {FGI_PROCESSED_FILE}. Total bars: {len(fgi_df)}\")\n",
        "        return fgi_df\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Error during API request: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def load_and_clean_ta_data():\n",
        "    \"\"\"Loads, cleans, filters, and saves the Technical Analysis data.\"\"\"\n",
        "    try:\n",
        "        # 1. Load Price and TA Data\n",
        "        data = pd.read_csv(PROCESSED_FILE, index_col=0, parse_dates=True)\n",
        "\n",
        "        # 2. Selecting and standardizing core columns\n",
        "        data_for_bt = data[['Close', 'ATR', 'RSI', 'EMA_20', 'MACD', 'MACD_Signal', 'Close_Lag_1']].copy()\n",
        "        data_for_bt.columns = ['Close', 'ATR', 'RSI', 'EMA_20', 'MACD', 'MACD_Signal', 'Close_Lag_1']\n",
        "        data_for_bt.dropna(inplace=True)\n",
        "        data_for_bt.sort_index(inplace=True)\n",
        "\n",
        "        # 3. APPLY THE CRITICAL DATE FILTER\n",
        "        # This limits the TA data to the period we are interested in for backtesting.\n",
        "        data_for_bt = data_for_bt.loc[START_DATE_FILTER:].copy()\n",
        "\n",
        "        # 4. SAVE the cleaned DataFrame\n",
        "        data_for_bt.to_csv(CLEANED_TA_FILE, index=True)\n",
        "\n",
        "        print(f\"‚úÖ Price and TA data loaded and cleaned successfully.\")\n",
        "        print(f\"‚úÖ Data filtered starting from {START_DATE_FILTER}.\")\n",
        "        print(f\"‚úÖ Cleaned TA data SAVED to: {CLEANED_TA_FILE}. Total usable bars: {len(data_for_bt)}\")\n",
        "        return data_for_bt\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: Processed data file not found at {PROCESSED_FILE}.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during TA data loading and saving: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- EXECUTION ---\n",
        "ta_df = load_and_clean_ta_data()\n",
        "fgi_df = fetch_and_process_fgi_data()\n",
        "\n",
        "if ta_df is not None and fgi_df is not None:\n",
        "    print(\"\\n--- Data files ready for merging. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p7yJz3lI4XI",
        "outputId": "bd60f5da-02c1-49ed-d0ab-8db35c525375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Price and TA data loaded and cleaned successfully.\n",
            "‚úÖ Data filtered starting from 2023-01-01.\n",
            "‚úÖ Cleaned TA data SAVED to: /content/drive/MyDrive/ColabNotebooks/Proj5/data_btc/btc_cleaned_ta_data.csv. Total usable bars: 1006\n",
            "‚è≥ Fetching historical F&G Index data...\n",
            "‚úÖ FGI data retrieved and saved to /content/drive/MyDrive/ColabNotebooks/Proj5/data_btc/btc_fgi_data.csv. Total bars: 2831\n",
            "\n",
            "--- Data files ready for merging. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####<b>Final Merge TA and Sentiment Data</b>"
      ],
      "metadata": {
        "id": "bxQkBFSsPZSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -------------------------------------------------------------- ##\n",
        "#  FINAL MERGE AND GLOBAL DATA PREPARATION\n",
        "# --- Using the previously confirmed working pd.DataFrame.merge method ---\n",
        "## -------------------------------------------------------------- ##\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "SAVE_FOLDER = '/content/drive/MyDrive/ColabNotebooks/Proj5/data_btc'\n",
        "CLEANED_TA_FILE = os.path.join(SAVE_FOLDER, \"btc_cleaned_ta_data.csv\")\n",
        "FGI_PROCESSED_FILE = os.path.join(SAVE_FOLDER, \"btc_fgi_data.csv\")\n",
        "FINAL_MERGED_FILE = os.path.join(SAVE_FOLDER, \"btc_final_merged_data.csv\")\n",
        "\n",
        "# Global variable to hold the final merged data for the strategy\n",
        "data_for_bt = None\n",
        "\n",
        "def merge_and_save_final_data():\n",
        "    \"\"\"\n",
        "    Loads CLEANED TA data and FGI data, performs a Left Merge using the Date index,\n",
        "    fills missing FGI dates conservatively, and saves the final file.\n",
        "    \"\"\"\n",
        "    global data_for_bt\n",
        "\n",
        "    try:\n",
        "        # 1. Load CLEANED TA Data (The Master DataFrame)\n",
        "        data_for_bt_local = pd.read_csv(CLEANED_TA_FILE, index_col=0, parse_dates=True)\n",
        "        data_for_bt_local.sort_index(inplace=True)\n",
        "\n",
        "        if data_for_bt_local.empty:\n",
        "            print(f\"‚ùå Error: Cleaned TA data file at {CLEANED_TA_FILE} is empty.\")\n",
        "            return\n",
        "\n",
        "        # 2. Load FGI Data\n",
        "        fgi_df = pd.read_csv(FGI_PROCESSED_FILE, index_col=0, parse_dates=True)\n",
        "        fgi_df.sort_index(inplace=True)\n",
        "\n",
        "        # 3. Perform Left Merge using the index (Date)\n",
        "        # We merge the FGI data onto the TA data (data_for_bt_local).\n",
        "        merged_df = data_for_bt_local.merge(fgi_df[['FGI_Score', 'FGI_Sentiment']],\n",
        "                                            left_index=True,  # Match using the index of the left df (TA)\n",
        "                                            right_index=True, # Match using the index of the right df (FGI)\n",
        "                                            how='left')       # Keep all TA rows\n",
        "\n",
        "        # 4. Handle Missing FGI Data (Fill conservatively)\n",
        "        merged_df['FGI_Score'].fillna(50, inplace=True)\n",
        "        merged_df['FGI_Sentiment'].fillna('Neutral', inplace=True)\n",
        "\n",
        "        # 5. Save the Final Combined Data to a new file üíæ\n",
        "        merged_df.to_csv(FINAL_MERGED_FILE, index=True)\n",
        "\n",
        "        # Update the global variable for the next code cell\n",
        "        data_for_bt = merged_df\n",
        "\n",
        "        print(f\"‚úÖ TA and Sentiment data merged and saved to {FINAL_MERGED_FILE}.\")\n",
        "        print(f\"   Total bars after merge: {len(data_for_bt)}\")\n",
        "        print(f\"   Date range: {data_for_bt.index.min().date()} to {data_for_bt.index.max().date()}\")\n",
        "\n",
        "        # Display the head and tail for confirmation\n",
        "        print(\"\\n--- Merged Data Head (2023 History Confirmed) ---\")\n",
        "        print(data_for_bt[['Close', 'RSI', 'FGI_Score', 'FGI_Sentiment']].head())\n",
        "        print(\"\\n--- Merged Data Tail (Recent FGI Scores Confirmed) ---\")\n",
        "        print(data_for_bt[['Close', 'RSI', 'FGI_Score', 'FGI_Sentiment']].tail())\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"‚ùå Error: Required file not found. Check if '{e.filename}' exists.\")\n",
        "        print(\"Ensure Block 1 (TA and FGI preparation) was run and saved the files correctly.\")\n",
        "    except KeyError as e:\n",
        "        print(f\"‚ùå FINAL ERROR: Column {e} not found. Please check column names in the FGI CSV file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå An unexpected error occurred during data merging and saving: {e}\")\n",
        "\n",
        "# --- EXECUTION ---\n",
        "merge_and_save_final_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZe8QucVI4U2",
        "outputId": "18e74881-7d4f-48e3-cc99-b704a7d2324c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TA and Sentiment data merged and saved to /content/drive/MyDrive/ColabNotebooks/Proj5/data_btc/btc_final_merged_data.csv.\n",
            "   Total bars after merge: 1006\n",
            "   Date range: 2023-02-03 to 2025-11-05\n",
            "\n",
            "--- Merged Data Head (2023 History Confirmed) ---\n",
            "                   Close        RSI  FGI_Score FGI_Sentiment\n",
            "Date                                                        \n",
            "2023-02-03  23449.322266  71.088891       60.0         Greed\n",
            "2023-02-04  23331.847656  69.238110       58.0         Greed\n",
            "2023-02-05  22955.666016  63.533881       58.0         Greed\n",
            "2023-02-06  22760.109375  60.732744       56.0         Greed\n",
            "2023-02-07  23264.291016  65.015328       54.0       Neutral\n",
            "\n",
            "--- Merged Data Tail (Recent FGI Scores Confirmed) ---\n",
            "                    Close        RSI  FGI_Score FGI_Sentiment\n",
            "Date                                                         \n",
            "2025-10-31  109556.164062  44.513921       29.0          Fear\n",
            "2025-11-01  110064.015625  45.727378       33.0          Fear\n",
            "2025-11-02  110639.625000  47.138472       37.0          Fear\n",
            "2025-11-03  106547.523438  39.312941       42.0          Fear\n",
            "2025-11-05  103714.414062  34.982867       23.0  Extreme Fear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Rule-Based Adaptive Multiplier</b>\n",
        "Source: https://www.youtube.com/watch?v=nzpIhdvDyyo"
      ],
      "metadata": {
        "id": "fYOYn09GNdIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ---------------------------------------------------------------- ##\n",
        "# SIMPLIFIED RULE-BASED ADAPTIVE MULTIPLIER\n",
        "# --- Focuses only on MACD Trend and FGI Extremes ---\n",
        "## ---------------------------------------------------------------- ##\n",
        "\n",
        "def get_rule_based_multiplier(current_data: pd.Series, combined_action: str) -> float:\n",
        "    \"\"\"\n",
        "    Generates a simplified contextual risk multiplier (0.0 to 1.5) by checking\n",
        "    if MACD trend and FGI extremes confirm the combined trading action.\n",
        "    \"\"\"\n",
        "\n",
        "    rsi = current_data['RSI']\n",
        "    macd_delta = current_data['MACD'] - current_data['MACD_Signal']\n",
        "    fgi_score = current_data['FGI_Score']\n",
        "\n",
        "    # Base Multiplier: Neutral starting point\n",
        "    multiplier = 1.0\n",
        "\n",
        "    # Check if the core action is a BUY/LONG\n",
        "    is_long_action = 'BUY' in combined_action.upper() or 'LONG' in combined_action.upper()\n",
        "\n",
        "    # If the strategy is FLAT, exit immediately\n",
        "    if 'FLAT' in combined_action.upper() or 'HOLD' in combined_action.upper():\n",
        "        return 1.0\n",
        "\n",
        "    # --- 1. MACD Trend Confirmation (Adds/Subtracts 0.2) ---\n",
        "    # The MACD delta should align with the trade direction.\n",
        "    if (is_long_action and macd_delta > 0) or (not is_long_action and macd_delta < 0):\n",
        "        # Trend Confirms Action\n",
        "        multiplier += 0.2\n",
        "    else:\n",
        "        # Trend Contradicts Action (Trading against momentum is riskier)\n",
        "        multiplier -= 0.2\n",
        "\n",
        "    # --- 2. FGI Extreme Sentiment (Adds/Subtracts 0.3) ---\n",
        "    # We look for contrarian signals (Fear for Buys, Greed for Sells)\n",
        "    if fgi_score <= 30: # Extreme Fear (Contrarian Buy Signal)\n",
        "        multiplier += (0.3 if is_long_action else -0.3)\n",
        "    elif fgi_score >= 70: # Extreme Greed (Contrarian Sell Signal)\n",
        "        multiplier += (-0.3 if is_long_action else 0.3)\n",
        "\n",
        "    # --- 3. RSI Over-extension Filter (Adds/Subtracts 0.1) ---\n",
        "    # Punish the trade if momentum is exhausted (RSI is too high for a Buy, too low for a Sell)\n",
        "    if (is_long_action and rsi >= 75) or (not is_long_action and rsi <= 25):\n",
        "        multiplier -= 0.1\n",
        "    elif (is_long_action and rsi <= 30) or (not is_long_action and rsi >= 70):\n",
        "        multiplier += 0.1 # Reward entering at oversold/overbought extremes\n",
        "\n",
        "    # 4. Clamp the output to ensure it stays within the required range\n",
        "    final_multiplier = max(0.0, min(1.5, multiplier))\n",
        "\n",
        "    return final_multiplier\n",
        "\n",
        "# Assign the rule-based function to the name expected by Block 4\n",
        "get_final_multiplier = get_rule_based_multiplier\n",
        "\n",
        "# print(\"\\n--- Simplified Rule-Based Adaptive Multiplier Function Defined ---\")\n",
        "# print(\"This function is now stable and ready for integration into the strategy.\")"
      ],
      "metadata": {
        "id": "zIpc9LRUeE3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b> Trading Global Configuration </b>"
      ],
      "metadata": {
        "id": "CT677_ZWIT-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- GLOBAL SYSTEM CONFIGURATION ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "# Financial Parameters\n",
        "STARTING_BUDGET = 100000.0 # Configurable initial budget\n",
        "COMMISSION_RATE = 0.002\n",
        "RISK_FREE_RATE_ANNUAL = 0.04\n",
        "DCA_AMOUNT_DAILY = 100.0   # Base daily accumulation amount\n",
        "ATR_MULTIPLIER = 3.0       # Stop-loss risk factor for tactical trades\n",
        "\n",
        "# Strategy Parameters (TA-Based Rules)\n",
        "RSI_OVERSOLD_THRESHOLD = 30 # Threshold for potential \"Value/Range\" accumulation\n",
        "RSI_OVERBOUGHT_THRESHOLD = 70 # Threshold for potential \"Swing\" profit-taking\n",
        "SWING_TRADE_ALLOCATION_MAX = 0.60 # Max percentage of budget for active trades"
      ],
      "metadata": {
        "id": "E3CdEFXYq2X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b> Dynamic Trading Strategy </b>"
      ],
      "metadata": {
        "id": "MVf2aQvm8zPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -------------------------------------------------------------- ##\n",
        "# ----- CORE EXECUTION FUNCTIONS (MODIFIES PORTFOLIO) -----\n",
        "## -------------------------------------------------------------- ##\n",
        "import pandas as pd\n",
        "# Assume global variables (DCA_AMOUNT_DAILY, ATR_MULTIPLIER, COMMISSION_RATE, etc.) are available\n",
        "\n",
        "def execute_dca_buy(row, portfolio: dict) -> bool:\n",
        "    \"\"\"Executes a daily DCA buy and modifies the portfolio state.\"\"\"\n",
        "    global DCA_AMOUNT_DAILY, COMMISSION_RATE, RSI_OVERSOLD_THRESHOLD\n",
        "\n",
        "    current_close = row['Close']\n",
        "    dca_amount = DCA_AMOUNT_DAILY\n",
        "\n",
        "    # Conditional DCA: Increase buy size during accumulation periods\n",
        "    if row['RSI'] < RSI_OVERSOLD_THRESHOLD:\n",
        "        dca_amount *= 1.5\n",
        "\n",
        "    if portfolio['cash'] >= dca_amount:\n",
        "        commission = dca_amount * COMMISSION_RATE\n",
        "        buy_qty = (dca_amount - commission) / current_close\n",
        "\n",
        "        # Update portfolio directly\n",
        "        portfolio['cash'] -= dca_amount\n",
        "        portfolio['btc_qty'] += buy_qty\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def open_tactical_trade(row, portfolio: dict, allocation_pct: float) -> bool:\n",
        "    \"\"\"Opens a tactical position and modifies the portfolio state.\"\"\"\n",
        "    global ATR_MULTIPLIER, COMMISSION_RATE\n",
        "\n",
        "    if portfolio.get('swing_qty', 0.0) > 0:\n",
        "        return False\n",
        "\n",
        "    trade_budget = portfolio['cash'] * allocation_pct\n",
        "\n",
        "    if trade_budget > 0:\n",
        "        entry_price = row['Close']\n",
        "        commission = trade_budget * COMMISSION_RATE\n",
        "        buy_qty = (trade_budget - commission) / entry_price\n",
        "\n",
        "        # ATR Stop Loss Calculation\n",
        "        stop_loss_level = entry_price - (row['ATR'] * ATR_MULTIPLIER)\n",
        "\n",
        "        # Update portfolio directly\n",
        "        portfolio['cash'] -= trade_budget\n",
        "        portfolio['btc_qty'] += buy_qty\n",
        "        portfolio['swing_qty'] = buy_qty\n",
        "        portfolio['swing_entry_price'] = entry_price\n",
        "        portfolio['stop_loss_level'] = stop_loss_level\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def close_tactical_trade(row, portfolio: dict, final_action: str) -> bool:\n",
        "    \"\"\"Determines and executes the parameters for closing the tactical trade (SL or TP).\"\"\"\n",
        "    global COMMISSION_RATE\n",
        "\n",
        "    if portfolio.get('swing_qty', 0.0) == 0.0:\n",
        "        return False\n",
        "\n",
        "    btc_to_sell = portfolio['swing_qty']\n",
        "    current_close = row['Close']\n",
        "    entry_price = portfolio['swing_entry_price']\n",
        "\n",
        "    # Condition 1: STOP-LOSS CHECK (Risk Management Override)\n",
        "    if current_close < portfolio['stop_loss_level']:\n",
        "        exit_price = portfolio['stop_loss_level']\n",
        "\n",
        "    # Condition 2: PROFIT-TAKE CHECK (Strategy Driven)\n",
        "    elif current_close >= entry_price * 1.05 and \\\n",
        "      ('BUY' not in final_action): # If profitable AND the new day's signal is not a strong BUY/LONG\n",
        "      exit_price = current_close\n",
        "\n",
        "    else:\n",
        "        return False # No exit condition met\n",
        "\n",
        "    # Execute Sale\n",
        "    sale_usd = btc_to_sell * exit_price\n",
        "    commission = sale_usd * COMMISSION_RATE\n",
        "\n",
        "    # Update portfolio directly\n",
        "    portfolio['cash'] += sale_usd - commission\n",
        "    portfolio['btc_qty'] -= btc_to_sell\n",
        "    portfolio['swing_qty'] = 0.0\n",
        "    portfolio['stop_loss_level'] = 0.0\n",
        "\n",
        "    return True\n",
        "\n",
        "# print(\"‚úÖ Execution functions updated to modify the portfolio state directly.\")"
      ],
      "metadata": {
        "id": "HhhPrwL88znn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b>Combined Strategy Decision Engine</b>"
      ],
      "metadata": {
        "id": "wfjZYqlIeFR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## -------------------------------------------------------------- ##\n",
        "# COMBINED STRATEGY (MASTER DECIDER AND EXECUTOR)\n",
        "# --- Updated: Removed dependency on 'decide_strategy' and integrated TA logic ---\n",
        "## -------------------------------------------------------------- ##\n",
        "\n",
        "\n",
        "def get_combined_signal_and_execute(current_data: pd.Series, portfolio: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Combines TA (in-line) and Sentiment, applies the Adaptive Multiplier,\n",
        "    makes the final decision, and executes the trade by modifying the portfolio.\n",
        "    \"\"\"\n",
        "    global SWING_TRADE_ALLOCATION_MAX\n",
        "\n",
        "    # --- 1. BASE DECISION LOGIC (TA and Sentiment Score Calculation) ---\n",
        "\n",
        "    # 1.1 Calculate TA Mode In-Line (REPLACEMENT FOR decide_strategy)\n",
        "    rsi = current_data['RSI']\n",
        "    macd_delta = current_data['MACD'] - current_data['MACD_Signal']\n",
        "\n",
        "    if macd_delta > 0 and rsi > 55:\n",
        "        # Strong Momentum, suggests swinging\n",
        "        ta_mode = 'SWING_TRADE'\n",
        "    elif rsi < 50 and rsi > 30 and abs(macd_delta) < 0.1:\n",
        "        # Low momentum, likely consolidation/range\n",
        "        ta_mode = 'RANGE_BOUND'\n",
        "    else:\n",
        "        ta_mode = 'NEUTRAL'\n",
        "\n",
        "    # 1.2 Calculate Scores\n",
        "    fgi_score = current_data['FGI_Score']\n",
        "\n",
        "    sentiment_score = 0\n",
        "    if fgi_score <= 24: sentiment_score = 2\n",
        "    elif fgi_score <= 49: sentiment_score = 1\n",
        "    elif fgi_score >= 75: sentiment_score = -1\n",
        "\n",
        "    ta_score = 0\n",
        "    if ta_mode == 'SWING_TRADE': ta_score = 2\n",
        "    elif ta_mode == 'RANGE_BOUND': ta_score = 1\n",
        "    # NEUTRAL ta_mode implicitly gives ta_score = 0\n",
        "\n",
        "    combined_score = ta_score + sentiment_score\n",
        "\n",
        "    # 1.3 Determine Final Action and Base Allocation\n",
        "    if combined_score >= 4:\n",
        "        final_action = \"AGGRESSIVE_BUY\"\n",
        "        base_allocation_pct = SWING_TRADE_ALLOCATION_MAX # Base 100% of max\n",
        "    elif combined_score >= 2:\n",
        "        final_action = \"MODERATE_BUY\"\n",
        "        base_allocation_pct = SWING_TRADE_ALLOCATION_MAX * 0.5 # Base 50% of max\n",
        "    elif combined_score <= -1:\n",
        "        final_action = \"AVOID_ENTRY\"\n",
        "        base_allocation_pct = 0.0\n",
        "    else:\n",
        "        final_action = \"HOLD_DCA_ONLY\"\n",
        "        base_allocation_pct = 0.0\n",
        "\n",
        "    # --- 2. MULTIPLIER CALCULATION AND APPLICATION ---\n",
        "\n",
        "    # Only calculate and apply the multiplier if there is a potential BUY action\n",
        "    if 'BUY' in final_action:\n",
        "        # Get the adaptive risk multiplier from the stable rule-based function\n",
        "        risk_multiplier = get_final_multiplier(current_data, final_action)\n",
        "\n",
        "        # Apply the multiplier to the base trade size\n",
        "        allocation_pct = base_allocation_pct * risk_multiplier\n",
        "\n",
        "        # Final safety clamp: Ensure we don't exceed the global max allocation\n",
        "        allocation_pct = min(allocation_pct, SWING_TRADE_ALLOCATION_MAX)\n",
        "\n",
        "        # If the multiplier drops the trade size too low, update the action description\n",
        "        if allocation_pct < SWING_TRADE_ALLOCATION_MAX * 0.1:\n",
        "             final_action = f\"RISK_BLOCKED_{final_action}\"\n",
        "    else:\n",
        "        allocation_pct = base_allocation_pct\n",
        "        risk_multiplier = 1.0 # For reporting purposes\n",
        "\n",
        "    # --- 3. EXECUTION LOGIC ---\n",
        "    trade_occurred = False\n",
        "\n",
        "    # Use a variable for the action string to pass to execution functions\n",
        "    current_final_action = final_action\n",
        "\n",
        "    # A. Execute Exits (Must check this first)\n",
        "    if close_tactical_trade(current_data, portfolio, current_final_action):\n",
        "        trade_occurred = True\n",
        "\n",
        "    # B. Execute DCA Buy (Usually runs regardless of tactical signal)\n",
        "    if execute_dca_buy(current_data, portfolio):\n",
        "        trade_occurred = True\n",
        "\n",
        "    # C. Execute TACTICAL Entry (Driven by the final_action and calculated allocation_pct)\n",
        "    if 'BUY' in current_final_action and portfolio['swing_qty'] == 0.0 and allocation_pct > 0:\n",
        "        if open_tactical_trade(current_data, portfolio, allocation_pct):\n",
        "            trade_occurred = True\n",
        "\n",
        "    return {\n",
        "        'final_action': final_action,\n",
        "        'trade_occurred': trade_occurred,\n",
        "        'ta_mode': ta_mode,\n",
        "        'fgi_score': fgi_score,\n",
        "        'multiplier': risk_multiplier,\n",
        "        'final_allocation_pct': allocation_pct\n",
        "    }\n",
        "\n",
        "# print(\"‚úÖ Block 4: Combined strategy function successfully updated. Dependency on 'decide_strategy' is removed.\")"
      ],
      "metadata": {
        "id": "m2ccWAKLeEnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vzuEfrDIeHAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### <b> Full Strategy Sanity Check </b>"
      ],
      "metadata": {
        "id": "uUwLXw0mHMaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ---------------------------------------------------------------- ##\n",
        "#     FULL STRATEGY SANITY CHECK (LAST 120 DAYS)\n",
        "# --- Verifies the combined decision, sentiment, and multiplier logic ---\n",
        "## ---------------------------------------------------------------- ##\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# Global variable data_for_bt is assumed to be loaded and prepared from Cell 1.2\n",
        "# Strategy functions (decide_strategy, get_combined_signal_and_execute, etc.) are assumed to be defined.\n",
        "\n",
        "LOOKBACK_DAYS = 120\n",
        "\n",
        "# 1. Prepare Data: Select the last 120 bars\n",
        "sanity_check_data = data_for_bt.tail(LOOKBACK_DAYS).copy() # Use .copy() for safety\n",
        "\n",
        "if sanity_check_data.empty or len(sanity_check_data) < LOOKBACK_DAYS:\n",
        "    print(f\"‚ùå Error: Insufficient data. Need at least {LOOKBACK_DAYS} days.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# 2. Apply the get_combined_signal_and_execute function to every row\n",
        "# We will use a dummy portfolio as the function requires one,\n",
        "# but the portfolio state won't persist across days in this sanity check loop.\n",
        "strategy_results = []\n",
        "# Initialize a dummy portfolio that doesn't change state during this check\n",
        "DUMMY_PORTFOLIO = {\n",
        "    'cash': 100000.0,\n",
        "    'btc_qty': 0.0,\n",
        "    'swing_qty': 0.0,\n",
        "    'swing_entry_price': 0.0,\n",
        "    'stop_loss_level': 0.0,\n",
        "}\n",
        "\n",
        "print(\"Running full combined strategy check on the last 120 days...\")\n",
        "for index, row in sanity_check_data.iterrows():\n",
        "    # Use the master execution function (read-only mode)\n",
        "    result = get_combined_signal_and_execute(row, DUMMY_PORTFOLIO.copy())\n",
        "\n",
        "    # Store relevant metrics from the result dictionary\n",
        "    strategy_results.append({\n",
        "        'Date': index,\n",
        "        'Close': row['Close'],\n",
        "        'TA_Mode': result['ta_mode'],\n",
        "        'FGI_Score': result['fgi_score'],\n",
        "        'Final_Action': result['final_action'],\n",
        "        'Risk_Multiplier': result['multiplier'],\n",
        "        'Final_Allocation_Pct': result['final_allocation_pct'],\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(strategy_results).set_index('Date')\n",
        "\n",
        "\n",
        "# 3. ANALYSIS AND OUTPUT\n",
        "print(\"\\n=========================================================\")\n",
        "print(f\" Full Adaptive Strategy Sanity Check: Last {LOOKBACK_DAYS} Days\")\n",
        "print(\"=========================================================\")\n",
        "\n",
        "# A. Final Action Frequency (Strategy Bias)\n",
        "print(\"\\n--- Final Action Frequency (Market View) ---\")\n",
        "print(\"Shows how often the combined system decided on each action.\")\n",
        "action_frequency = results_df['Final_Action'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'\n",
        "print(action_frequency)\n",
        "\n",
        "# B. Risk Multiplier Impact\n",
        "print(\"\\n--- Risk Assessment Impact ---\")\n",
        "print(f\"Price Change over {LOOKBACK_DAYS} days: {((results_df['Close'].iloc[-1] / results_df['Close'].iloc[0]) - 1) * 100:.2f}%\")\n",
        "print(f\"Average FGI Score: {results_df['FGI_Score'].mean():.1f}\")\n",
        "print(f\"Average Risk Multiplier: {results_df['Risk_Multiplier'].mean():.3f} (Neutral is 1.0)\")\n",
        "print(f\"Avg. Final Allocation (Adjusted): {results_df['Final_Allocation_Pct'].mean() * 100:.2f}%\")\n",
        "\n",
        "\n",
        "# C. Current Day Decision (Immediate Action)\n",
        "last_day = results_df.iloc[-1]\n",
        "print(\"\\n--- Today's Full Strategy Decision ---\")\n",
        "print(f\"Date: {last_day.name.strftime('%Y-%m-%d')}\")\n",
        "print(f\"TA Mode: {last_day['TA_Mode']}\")\n",
        "print(f\"FGI Score: {last_day['FGI_Score']:.0f}\")\n",
        "print(f\"Final Action: {last_day['Final_Action']}\")\n",
        "print(f\"Multiplier Applied: {last_day['Risk_Multiplier']:.3f}\")\n",
        "print(f\"Final Entry Allocation: {last_day['Final_Allocation_Pct'] * 100:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE4ux3KbT2nR",
        "outputId": "ca383298-f347-483c-ec55-79bcf63cdc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full combined strategy check on the last 120 days...\n",
            "\n",
            "=========================================================\n",
            " Full Adaptive Strategy Sanity Check: Last 120 Days\n",
            "=========================================================\n",
            "\n",
            "--- Final Action Frequency (Market View) ---\n",
            "Shows how often the combined system decided on each action.\n",
            "Final_Action\n",
            "MODERATE_BUY       65.0%\n",
            "HOLD_DCA_ONLY     31.67%\n",
            "AVOID_ENTRY        1.67%\n",
            "AGGRESSIVE_BUY     1.67%\n",
            "Name: proportion, dtype: object\n",
            "\n",
            "--- Risk Assessment Impact ---\n",
            "Price Change over 120 days: -4.81%\n",
            "Average FGI Score: 53.8\n",
            "Average Risk Multiplier: 1.010 (Neutral is 1.0)\n",
            "Avg. Final Allocation (Adjusted): 20.70%\n",
            "\n",
            "--- Today's Full Strategy Decision ---\n",
            "Date: 2025-11-05\n",
            "TA Mode: NEUTRAL\n",
            "FGI Score: 23\n",
            "Final Action: MODERATE_BUY\n",
            "Multiplier Applied: 1.100\n",
            "Final Entry Allocation: 33.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWl9T4vclo2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <b> Backtesting </b>\n",
        "<b> Backtesting 1: </b> In-Sample (IS) - period from 2023-11-01 to 2024-10-31<br>\n",
        " <b> Backtesting 2: </b> Out-of-Sample (OOS) - period from 2024-11-01 to 2025-10-31"
      ],
      "metadata": {
        "id": "ystrfGlrIu0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ---------------------------------------------------------------- ##\n",
        "# --- FINAL BACKTESTING ENGINE (SIMPLE CALL) ---\n",
        "## ---------------------------------------------------------------- ##\n",
        "\n",
        "# Assume global variables: STARTING_BUDGET, RISK_FREE_RATE_ANNUAL\n",
        "# Assume file path: FINAL_MERGED_FILE\n",
        "\n",
        "def run_simplified_backtest(start_date_str, end_date_str):\n",
        "    \"\"\"\n",
        "    Runs the backtest simulation by only calling the combined strategy function.\n",
        "    \"\"\"\n",
        "    global STARTING_BUDGET, RISK_FREE_RATE_ANNUAL\n",
        "\n",
        "    # 1. Load Correct Data\n",
        "    try:\n",
        "        data_for_bt_local = pd.read_csv(FINAL_MERGED_FILE, index_col=0, parse_dates=True)\n",
        "        data_sim = data_for_bt_local.loc[start_date_str:end_date_str].copy()\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå Error: Final merged data file not found at {FINAL_MERGED_FILE}. Cannot proceed.\")\n",
        "        return None\n",
        "    except Exception:\n",
        "        print(f\"‚ùå Error: Date range {start_date_str} to {end_date_str} failed to slice.\")\n",
        "        return None\n",
        "\n",
        "    if len(data_sim) <= 1:\n",
        "        print(f\"‚ùå Data slice for {start_date_str} to {end_date_str} is too short.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\" BACKTEST: {start_date_str} to {end_date_str}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 2. Initialize Portfolio State and Metrics\n",
        "    portfolio = {\n",
        "        'cash': STARTING_BUDGET,\n",
        "        'btc_qty': 0.0,\n",
        "        'swing_qty': 0.0,\n",
        "        'swing_entry_price': 0.0,\n",
        "        'stop_loss_level': 0.0,\n",
        "    }\n",
        "    portfolio_value_history = [STARTING_BUDGET]\n",
        "    total_trades = 0\n",
        "\n",
        "    # 3. Main Execution Loop\n",
        "    for date, row in data_sim.iloc[1:].iterrows():\n",
        "        current_close = row['Close']\n",
        "\n",
        "        # --- THE ONLY CALL REQUIRED ---\n",
        "        signal_results = get_combined_signal_and_execute(row, portfolio)\n",
        "\n",
        "        if signal_results['trade_occurred']:\n",
        "            total_trades += 1\n",
        "\n",
        "        # Log Performance\n",
        "        total_btc_value = portfolio['btc_qty'] * current_close\n",
        "        current_total_value = portfolio['cash'] + total_btc_value\n",
        "        portfolio_value_history.append(current_total_value)\n",
        "\n",
        "    # 4. Final Metrics Calculation (Streamlined)\n",
        "    port_series = pd.Series(portfolio_value_history, index=data_sim.index)\n",
        "\n",
        "    final_value = port_series.iloc[-1]\n",
        "    total_return_pct = ((final_value - STARTING_BUDGET) / STARTING_BUDGET) * 100\n",
        "\n",
        "    cumulative_max = port_series.cummax()\n",
        "    drawdown = (port_series - cumulative_max) / cumulative_max\n",
        "    max_drawdown_pct = abs(drawdown.min()) * 100\n",
        "\n",
        "    daily_returns = port_series.pct_change().dropna()\n",
        "    sharpe_ratio = 0.0\n",
        "    if daily_returns.std() > 0:\n",
        "        daily_risk_free_rate = RISK_FREE_RATE_ANNUAL / 365\n",
        "        sharpe_ratio = (daily_returns.mean() - daily_risk_free_rate) / daily_returns.std() * np.sqrt(365)\n",
        "\n",
        "    duration = data_sim.index.max() - data_sim.index.min()\n",
        "\n",
        "    # 5. Print Results\n",
        "    print(f\"\\nRESULTS: Combined TA + Sentiment\")\n",
        "    print(f\"Start:                 {data_sim.index.min()}\")\n",
        "    print(f\"End:                   {data_sim.index.max()}\")\n",
        "    print(f\"Duration:              {duration}\")\n",
        "    print(\"-\" * 35)\n",
        "    print(f\"Return [%]:            {total_return_pct:.2f}\")\n",
        "    print(f\"Max. Drawdown [%]:     {-max_drawdown_pct:.2f}\")\n",
        "    print(f\"Sharpe Ratio:          {sharpe_ratio:.4f}\")\n",
        "    print(f\"Total Trades:          {total_trades}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    return port_series\n",
        "\n",
        "# --- EXECUTION ---\n",
        "# Backtesting 1: period from 2023/11/01 to 2024-10-31\n",
        "performance_bt1 = run_simplified_backtest(\"2023-11-01\", \"2024-10-31\")\n",
        "\n",
        "# Backtesting 2: period from 2024-11-01 to 2025-10-31\n",
        "performance_bt2 = run_simplified_backtest(\"2024-11-01\", \"2025-10-31\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEoUXcYACxbF",
        "outputId": "3791cb2c-3923-4c45-dd2b-a28741dbea5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            " BACKTEST: 2023-11-01 to 2024-10-31\n",
            "================================================================================\n",
            "\n",
            "RESULTS: Combined TA + Sentiment\n",
            "Start:                 2023-11-01 00:00:00\n",
            "End:                   2024-10-31 00:00:00\n",
            "Duration:              365 days 00:00:00\n",
            "-----------------------------------\n",
            "Return [%]:            17.14\n",
            "Max. Drawdown [%]:     -14.54\n",
            "Sharpe Ratio:          0.7535\n",
            "Total Trades:          365\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            " BACKTEST: 2024-11-01 to 2025-10-31\n",
            "================================================================================\n",
            "\n",
            "RESULTS: Combined TA + Sentiment\n",
            "Start:                 2024-11-01 00:00:00\n",
            "End:                   2025-10-31 00:00:00\n",
            "Duration:              364 days 00:00:00\n",
            "-----------------------------------\n",
            "Return [%]:            13.53\n",
            "Max. Drawdown [%]:     -8.79\n",
            "Sharpe Ratio:          0.6241\n",
            "Total Trades:          364\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### <b>Conclusion:</b> The combined TA + Sentiment strategy appears to be a strong performer in bullish, high-momentum environments (BT1) where trend-following and contrarian buys are effective. However, its effectiveness drops substantially in challenging, range-bound, or corrective markets (BT2), where it takes more risk for smaller gains."
      ],
      "metadata": {
        "id": "o38wi--lWhCv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiwBMzoOCxSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HlPb42WWliHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
